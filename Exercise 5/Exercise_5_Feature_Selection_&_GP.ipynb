{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e640b784-ad96-4608-b942-adf8212ee01f",
      "metadata": {
        "id": "e640b784-ad96-4608-b942-adf8212ee01f"
      },
      "source": [
        "# Sequential Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdedede9-ee6a-470d-84ca-c95304c4bb02",
      "metadata": {
        "id": "cdedede9-ee6a-470d-84ca-c95304c4bb02"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df_bcf = pd.read_csv(\"https://raw.githubusercontent.com/edgarsmdn/MLCE_book/main/references/BCF_training.csv\")\n",
        "\n",
        "df_bcf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d0d20f-b368-41de-ac7d-4cbc3ad9a68e",
      "metadata": {
        "id": "f8d0d20f-b368-41de-ac7d-4cbc3ad9a68e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score as R2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9cd2c48-842d-41b2-abc3-b49ce8235339",
      "metadata": {
        "id": "f9cd2c48-842d-41b2-abc3-b49ce8235339"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ed8ab7c-6257-4a72-ac35-283ad9988949",
      "metadata": {
        "id": "4ed8ab7c-6257-4a72-ac35-283ad9988949"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "X, y = df_bcf.iloc[:, 3:].values, df_bcf.iloc[:, 2].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train_std = sc.fit_transform(X_train)\n",
        "X_test_std = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "77352ec1-c680-4a5c-beb6-c24fe3f9ce1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77352ec1-c680-4a5c-beb6-c24fe3f9ce1b",
        "outputId": "588802ea-a416-4049-945b-6acd6470d305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE_train: 2.2080624428749998\n",
            "R2_train: -0.24141465919248084\n",
            "MSE_test: 2.191513343\n",
            "R2_test: -0.2546216866469089\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error as MSE,r2_score as R2\n",
        "\n",
        "model = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "model.fit(X_train_std, y_train)\n",
        "\n",
        "print('MSE_train:', MSE(y_train,model.predict(X_train)))\n",
        "print('R2_train:', R2(y_train,model.predict(X_train)))\n",
        "print('MSE_test:', MSE(y_test,model.predict(X_test)))\n",
        "print('R2_test:', R2(y_test,model.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456ef58c-8b7c-4c3d-a1f3-ba9ad9eb8d81",
      "metadata": {
        "id": "456ef58c-8b7c-4c3d-a1f3-ba9ad9eb8d81"
      },
      "source": [
        "## To understand how Sequential Feature selection works let's try Selecting the best 5 features for fixed k_neighbors using Scikit Learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
        "sfs_forward = SFS(model,\n",
        "          n_features_to_select=6,\n",
        "          direction='forward',\n",
        "          scoring='neg_mean_squared_error',\n",
        "          n_jobs=-1,\n",
        "          cv=5)\n",
        "sfs_forward = sfs_forward.fit(X_train_std, y_train)\n",
        "X_train_std_transformed = sfs_forward.transform(X_train_std)\n",
        "X_test_std_transformed = sfs_forward.transform(X_test_std)\n",
        "model_transformed = KNeighborsRegressor(n_neighbors=5)\n",
        "model_transformed.fit(X_train_std_transformed, y_train)\n",
        "# print('MSE_test_transformed:', i, MSE(y_test,model_transformed.predict(X_test_std_transformed)))\n",
        "print('R2_test_transformed:', R2(y_test,model_transformed.predict(X_test_std_transformed)))\n",
        "selected_features = sfs_forward.get_support()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxmQ9T93OcTg",
        "outputId": "935ea2ec-aec2-46bf-dc86-d48918fe49b0"
      },
      "id": "uxmQ9T93OcTg",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2_test_transformed: 0.7866219221290096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euy48OGJjVjD"
      },
      "source": [
        "## Rigorous features as well as k_neighbor search"
      ],
      "id": "Euy48OGJjVjD"
    },
    {
      "cell_type": "code",
      "source": [
        "#TRY YOURSELF"
      ],
      "metadata": {
        "id": "g-VHBTodOtET"
      },
      "id": "g-VHBTodOtET",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpImoxPkJA6o"
      },
      "source": [
        "#### **Gaussian Process using Numpy**"
      ],
      "id": "RpImoxPkJA6o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbbO5tyDVtz"
      },
      "source": [
        "#### Defining kernel"
      ],
      "id": "wgbbO5tyDVtz"
    },
    {
      "cell_type": "code",
      "source": [
        "def kernel(x1,x2,l=1.0,sigma=1.0):\n",
        "  d1 = (x1-x2.T)**2\n",
        "  out = sigma*np.exp(-d1/(2+l**2))\n",
        "  return out"
      ],
      "metadata": {
        "id": "rgWJ2X7lgeAT"
      },
      "id": "rgWJ2X7lgeAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVYuTc8bvgOm"
      },
      "source": [
        "#### Creating test set."
      ],
      "id": "UVYuTc8bvgOm"
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "n = 40\n",
        "x_test = np.linspace(-4,4,n).reshape(-1,1)"
      ],
      "metadata": {
        "id": "24X2e-YAvHL6"
      },
      "id": "24X2e-YAvHL6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_8B7Dl-vvH1"
      },
      "source": [
        "#### Prior Sampling"
      ],
      "id": "3_8B7Dl-vvH1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to know following derived expresions for kernels to implement Gaussian process\n",
        "\n",
        "\n",
        "*   k = kernel(x_train,x_train); explains similarities between training set among themselves\n",
        "*   k_star = kernel(x_train,x_test); explains similarities between train and test set\n",
        "*   k_star_star = kernel(x_test,x_test); explains similarities between test set among themselves\n",
        "*   k_inverse = np.linalg.inv(k)\n",
        "\n",
        "\n",
        "\n",
        "1.   m_post = k_star.T.dot(k_inverse).dot(y_train)          # mathematically defined predictions (mean) (see lecture slides)\n",
        "2.   cov_post = k_star_star - k_star.T.dot(k_inverse).dot(k_star)   # mathematically defined covariance matrix (see lecture slides)\n",
        "3.   std = np.sqrt(np.diag(cov_post)).reshape(m_post.shape)        # variance is always diagnol elements of covariance matrix\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zj91bVTYLumz"
      },
      "id": "zj91bVTYLumz"
    },
    {
      "cell_type": "code",
      "source": [
        "m = np.zeros(x_test.shape)\n",
        "cov = kernel(x_test,x_test)   # k_star_star\n",
        "prior_predictions = np.random.multivariate_normal(m.reshape(-1),cov,4)     #completely random without even knowing training data points)\n",
        "print(prior_predictions.shape,x_test.shape)"
      ],
      "metadata": {
        "id": "HfbwU_ss2zxK"
      },
      "id": "HfbwU_ss2zxK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bfPQLTi4rMl"
      },
      "source": [
        "#### Plotting Prior Samples/Predictions"
      ],
      "id": "7bfPQLTi4rMl"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x_test,prior_predictions.T)\n",
        "plt.xlim(-4,4)\n",
        "plt.ylim(-3,3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XxHFiCaa4yb4"
      },
      "id": "XxHFiCaa4yb4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iIGlKU_5jeK"
      },
      "source": [
        "#### Define training data"
      ],
      "id": "8iIGlKU_5jeK"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array([-3,-2,-1,1,2]).reshape(-1,1)\n",
        "y_train = np.cos(x_train)\n",
        "noise = 1e-07"
      ],
      "metadata": {
        "id": "Z21ga3-k5nFz"
      },
      "id": "Z21ga3-k5nFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pau4Rp6g59AR"
      },
      "source": [
        "#### Calculation of Posteriors"
      ],
      "id": "pau4Rp6g59AR"
    },
    {
      "cell_type": "code",
      "source": [
        "k = kernel(x_train,x_train)      # explains similarities between training set among themselves\n",
        "k_star = kernel(x_train,x_test)  # explains similarities between train and test set\n",
        "k_star_star = kernel(x_test,x_test)   # explains similarities between test set among themselves\n",
        "k_inverse = np.linalg.inv(k)"
      ],
      "metadata": {
        "id": "dJyfr3ki6CaE"
      },
      "id": "dJyfr3ki6CaE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok3r99937dAy"
      },
      "source": [
        "#### Posteriors mean and covariance matrix\n",
        "\n"
      ],
      "id": "ok3r99937dAy"
    },
    {
      "cell_type": "code",
      "source": [
        "m_post = k_star.T.dot(k_inverse).dot(y_train)          # mathematically defined predictions (mean) (see lecture slides)\n",
        "cov_post = k_star_star - k_star.T.dot(k_inverse).dot(k_star)   # mathematically defined covariance matrix (see lecture slides)\n",
        "std = np.sqrt(np.diag(cov_post)).reshape(m_post.shape)        # variance is always diagnol elements of covariance matrix"
      ],
      "metadata": {
        "id": "J9g5_mBQ7lOi"
      },
      "id": "J9g5_mBQ7lOi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BTunGuP9L0t"
      },
      "source": [
        "#### Draw posterior samples/predictions\n",
        "\n"
      ],
      "id": "7BTunGuP9L0t"
    },
    {
      "cell_type": "code",
      "source": [
        "posterior_predictions = np.random.multivariate_normal(m_post.ravel(),cov_post,4)"
      ],
      "metadata": {
        "id": "rUNUoWYo9Qgs"
      },
      "id": "rUNUoWYo9Qgs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGo87PXl-ktp"
      },
      "source": [
        "#### Plotting Posterior Samples/Predictions"
      ],
      "id": "cGo87PXl-ktp"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x_train,y_train,'o',ms=8)\n",
        "plt.plot(x_test,posterior_predictions.T,'--')\n",
        "plt.gca().fill_between(np.squeeze(x_test),np.squeeze(m_post - 1.96*std),np.squeeze(m_post + 1.96*std), color='aliceblue')\n",
        "plt.plot(x_test,m_post)\n",
        "plt.xlim(-4,4)\n",
        "plt.ylim(-3,3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8C6hwwlS-rnZ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8C6hwwlS-rnZ"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gca().fill_between(np.squeeze(x_test),np.squeeze(m_post - 1.96*std),np.squeeze(m_post + 1.96*std), color='aliceblue')\n",
        "plt.plot(x_test,m_post)\n",
        "plt.xlim(-4,4)\n",
        "plt.ylim(-3,3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x1z-9wE7-oeq"
      },
      "id": "x1z-9wE7-oeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTk8w7_RDexa"
      },
      "source": [
        "#### **Gaussian Process using Scikit Learn**"
      ],
      "id": "pTk8w7_RDexa"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import kernels, GaussianProcessRegressor\n",
        "np.random.seed(0)\n",
        "n = 40\n",
        "kernel_ = [kernels.RBF(),kernels.RationalQuadratic(),kernels.DotProduct(sigma_0=1.0)**2,kernels.RationalQuadratic()*kernels.Matern(),kernels.Matern()]"
      ],
      "metadata": {
        "id": "g6DvyEZMDh3W"
      },
      "id": "g6DvyEZMDh3W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for kernel in kernel_:\n",
        "  # implementation of Gaussian process\n",
        "  gp = GaussianProcessRegressor(kernel = kernel)\n",
        "\n",
        "  # defining test set\n",
        "  x_test = np.linspace(-4,4,n).reshape(-1,1)\n",
        "\n",
        "  # prior sample/predictions\n",
        "  m_prior, std_prior = gp.predict(x_test, return_std = True)\n",
        "  prior_predictions = gp.sample_y(x_test,2)\n",
        "\n",
        "  print('#'*50)\n",
        "  print(kernel)\n",
        "  print('#'*50)\n",
        "\n",
        "  # plotting the prior_predictions/samples (initilaization)\n",
        "  plt.figure(figsize = (10,3))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(x_test,m_prior)\n",
        "  plt.fill_between(x_test.ravel(),m_prior -std_prior, m_prior + std_prior, color = 'aliceblue')\n",
        "  plt.plot(x_test,prior_predictions, '--')\n",
        "  plt.title('prior')\n",
        "\n",
        "  # defining training dataset\n",
        "  x_train = np.array([-3,-2,-1,1,2]).reshape(-1,1)\n",
        "  y_train = np.cos(x_train)\n",
        "  gp.fit(x_train,y_train)\n",
        "\n",
        "  # posterior predictions\n",
        "  m_post, std_post = gp.predict(x_test,return_std=True)\n",
        "  m_post = m_post.reshape(-1)\n",
        "  post_predictions = np.squeeze(gp.sample_y(x_test,3))\n",
        "\n",
        "  # plotting the post_predictions/samples (initilaization)\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(x_test,m_post)\n",
        "  plt.scatter(x_train,y_train,color='blue',s=50)\n",
        "  plt.fill_between(x_test.ravel(),m_post -std_post, m_post + std_post, color = 'aliceblue')\n",
        "  plt.plot(x_test,post_predictions, '--')\n",
        "  plt.title('posterior')\n",
        "\n",
        "  print(\"gp.kernel_ : \" , gp.kernel_)\n",
        "  print(\"gp.log_marginal_likelihood : \" , gp.log_marginal_likelihood(gp.kernel_.theta))"
      ],
      "metadata": {
        "id": "xKSqkLXmEgIP"
      },
      "id": "xKSqkLXmEgIP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQK5RVg2MiVR"
      },
      "source": [
        "#### Let's try Linear Regression to approximate cosine function as we did above using Gaussian Process and see the difference"
      ],
      "id": "WQK5RVg2MiVR"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "np.random.seed(0)\n",
        "n = 40\n",
        "x_train = np.array([-3,-2,-1,1,2]).reshape(-1,1)\n",
        "x_test = np.linspace(-4,4,n).reshape(-1,1)\n",
        "y_train = np.cos(x_train)"
      ],
      "metadata": {
        "id": "r4YInyt0MaK1"
      },
      "id": "r4YInyt0MaK1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pf = PolynomialFeatures(degree=3)\n",
        "pf.fit(x_train)\n",
        "x_train_pf = pf.transform(x_train)\n",
        "x_test_pf = pf.transform(x_test)\n",
        "model = LinearRegression()\n",
        "model.fit(x_train_pf,y_train)\n",
        "y_pred_test = model.predict(x_test_pf)"
      ],
      "metadata": {
        "id": "KEJFQXZvNar3"
      },
      "id": "KEJFQXZvNar3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,3))\n",
        "plt.scatter(x_train,y_train,color='blue',s=50)\n",
        "plt.plot(x_test,y_pred_test, '--')\n",
        "plt.xlim(-4,4)\n",
        "plt.ylim(-5,2)"
      ],
      "metadata": {
        "id": "HbBMC-sdOZT1"
      },
      "id": "HbBMC-sdOZT1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrKRktqkPAZF"
      },
      "source": [
        "#### As we can see Linear regression has good intrapolation  but very poor extrapolation while GP can extrapolate well too if we use good kernels."
      ],
      "id": "rrKRktqkPAZF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BzEOleRPUkW"
      },
      "source": [
        "#### Let's try Gaussian Process on BCF dataset"
      ],
      "id": "3BzEOleRPUkW"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "X, y = df_bcf.iloc[:, 3:].values, df_bcf.iloc[:, 2].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# sc = StandardScaler()\n",
        "# X_train_std = sc.fit_transform(X_train)\n",
        "# X_test_std = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "W2PZPz-v_tS5"
      },
      "id": "W2PZPz-v_tS5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_ = [kernels.RationalQuadratic(alpha=0.25,length_scale=0.25)]\n",
        "# kernel_ = [kernels.RBF(),kernels.RationalQuadratic(),kernels.DotProduct(sigma_0=1.0)**2,kernels.RationalQuadratic()*kernels.Matern(),kernels.Matern()]\n"
      ],
      "metadata": {
        "id": "SlqovsKSFn6M"
      },
      "id": "SlqovsKSFn6M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for kernel in kernel_:\n",
        "  # implementation of Gaussian process\n",
        "  gp = GaussianProcessRegressor(kernel = kernel)\n",
        "\n",
        "  # defining test set\n",
        "  x_test = X_test_std\n",
        "\n",
        "  # prior sample/predictions\n",
        "  m_prior, std_prior = gp.predict(x_test, return_std = True)\n",
        "  prior_predictions = gp.sample_y(x_test,2)\n",
        "\n",
        "  print('#'*50)\n",
        "  print(kernel)\n",
        "  print('#'*50)\n",
        "\n",
        "\n",
        "  # defining training dataset\n",
        "  x_train = X_train_std\n",
        "  gp.fit(x_train,y_train)\n",
        "\n",
        "  # posterior predictions\n",
        "  m_post, std_post = gp.predict(x_test,return_std=True)\n",
        "  m_post = m_post.reshape(-1)\n",
        "  post_predictions = np.squeeze(gp.sample_y(x_test,3))\n",
        "  R2_score = R2(y_test, m_post)\n",
        "  print( R2_score)\n",
        "  plt.figure(figsize = (8,4))\n",
        "  plt.scatter(y_test,m_post)"
      ],
      "metadata": {
        "id": "pvMIKYDB_mCm"
      },
      "id": "pvMIKYDB_mCm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}